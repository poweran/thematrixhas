#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö HTML —Å—Ç—Ä–∞–Ω–∏—Ü —Ñ–æ—Ä—É–º–∞ aum.mybb.ru

–£–¥–∞–ª—è–µ—Ç:
- –í—Å–µ JavaScript —Å–∫—Ä–∏–ø—Ç—ã
- CSS —Å—Ç–∏–ª–∏ —Ñ–æ—Ä—É–º–∞
- –†–µ–∫–ª–∞–º—É (Yandex RTB –∏ –¥—Ä.)
- –ù–∞–≤–∏–≥–∞—Ü–∏—é, —Ñ–æ—Ä–º—ã, –º–µ–Ω—é
- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –ò–º–µ–Ω–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Ñ–æ—Ä—É–º–∞
- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∞–≤—Ç–æ—Ä–µ –ø–æ—Å—Ç–∞

–°–æ—Ö—Ä–∞–Ω—è–µ—Ç:
- –¢–µ–∫—Å—Ç –ø–æ—Å—Ç–æ–≤
- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Å–∫–∞—á–∏–≤–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ)
- –°–ø–æ–π–ª–µ—Ä—ã –∏ —Ü–∏—Ç–∞—Ç—ã (–±–µ–∑ –∏–º—ë–Ω)
- –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
"""

import re
import sys
import shutil
import hashlib
import os
try:
    import image_stitcher
except ImportError:
    image_stitcher = None
import urllib.request
import urllib.parse
from pathlib import Path
from html import unescape
from typing import Optional, List, Tuple

try:
    from bs4 import BeautifulSoup, NavigableString
except ImportError:
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ BeautifulSoup: pip install beautifulsoup4")
    sys.exit(1)


# –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π CSS –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
MINIMAL_CSS = """
body { font-family: Arial, sans-serif; background: #131833; color: #e0e0e0; line-height: 1.7; padding: 20px; max-width: 900px; margin: 0 auto; }
h1 { color: #FE99FE; text-align: center; }
.post { background: #1a1f3a; border-radius: 10px; padding: 20px; margin: 20px 0; }
.post-content { font-size: 14px; }
.post-content p { margin: 10px 0; }
img.postimg { max-width: 100%; height: auto; border-radius: 5px; }
img[title="float:right"] { float: right; padding-left: 12px; max-width: 40%; }
img[title="float:left"] { float: left; padding-right: 12px; max-width: 40%; }
.quote-box { background: rgba(0,0,0,0.3); border-left: 3px solid #FE99FE; padding: 15px; margin: 15px 0; border-radius: 0 8px 8px 0; }
.spoiler-box > div:first-child { cursor: pointer; color: #FE99FE; font-weight: bold; padding: 10px; background: rgba(0,0,0,0.2); border-radius: 5px; }
.spoiler-box > blockquote { display: none; padding: 15px; }
.spoiler-box.visible > blockquote { display: block; }
.clearer { clear: both; }
a { color: #FE99FE; }
.broken-link { color: #FF6666; text-decoration: underline dotted; cursor: help; }
"""


def fix_image_url(url: str) -> str:
    """
    –ò—Å–ø—Ä–∞–≤–∏—Ç—å –±–∏—Ç—ã–π URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    - &amp; ‚Üí —É–¥–∞–ª—è–µ—Ç—Å—è (–¥–ª—è Google Drive ?&id= ‚Üí ?id=)
    - –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç http ‚Üí https
    """
    if not url:
        return url
    
    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º HTML entities (&amp; ‚Üí &)
    url = unescape(url)
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–π & –ø–æ—Å–ª–µ ? (Google Drive: ?&id= ‚Üí ?id=)
    url = url.replace('?&', '?')
    
    # –£–±–∏—Ä–∞–µ–º –¥–≤–æ–π–Ω—ã–µ –∞–º–ø–µ—Ä—Å–∞–Ω–¥—ã
    url = re.sub(r'&+', '&', url)
    
    # http ‚Üí https
    if url.startswith('http://'):
        url = url.replace('http://', 'https://', 1)
    
    return url


def download_image(url: str, save_dir: Path) -> Optional[str]:
    """
    –°–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ URL –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ø–∞–ø–∫—É.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    """
    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ URL
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        parsed = urllib.parse.urlparse(url)
        path_ext = Path(parsed.path).suffix.lower()
        if path_ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.svg']:
            ext = path_ext
        else:
            ext = '.jpg'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        filename = f"img_{url_hash}{ext}"
        save_path = save_dir / filename
        
        # –ï—Å–ª–∏ —É–∂–µ —Å–∫–∞—á–∞–Ω–æ - –Ω–µ –∫–∞—á–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ
        if save_path.exists():
            return filename
        
        # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –Ω–µ—Ç
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # –°–∫–∞—á–∏–≤–∞–µ–º
        headers = {'User-Agent': 'Mozilla/5.0'}
        req = urllib.request.Request(url, headers=headers)
        
        with urllib.request.urlopen(req, timeout=10) as response:
            content = response.read()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            content_type = response.headers.get('Content-Type', '')
            if 'image' not in content_type and len(content) < 100:
                return None
            
            save_path.write_bytes(content)
            return filename
            
    except Exception as e:
        print(f"  ‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å {url[:50]}...: {e}")
        return None



class ImageModernizer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
    –ú–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å API (–Ω–∞–ø—Ä–∏–º–µ—Ä, Stability AI) –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏.
    """
    def __init__(self, api_key=None, use_local=False):
        self.api_key = api_key
        self.use_local = use_local
        self.pipeline = None
        
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç–∏–ª—è
        self.style_prompt = "modern clean aesthetic, high quality, 4k, detailed, professional photography, soft lighting"
        self.negative_prompt = "blurry, low quality, distorted, watermark, text, ugly"

    def _init_local_pipeline(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ Stable Diffusion"""
        if self.pipeline:
            return

        print("  ‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Stable Diffusion (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)...")
        try:
            import torch
            from diffusers import StableDiffusionImg2ImgPipeline
            
            model_id = "runwayml/stable-diffusion-v1-5"
            device = "cuda" if torch.cuda.is_available() else "cpu"
            dtype = torch.float16 if device == "cuda" else torch.float32
            
            self.pipeline = StableDiffusionImg2ImgPipeline.from_pretrained(
                model_id, 
                torch_dtype=dtype,
                use_safetensors=True
            ).to(device)
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
            if device == "cuda":
                self.pipeline.enable_attention_slicing()
                
            self.device = device
            print(f"  ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {device.upper()}")
            
        except ImportError:
            print("  ‚ùå –û—à–∏–±–∫–∞: –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã.")
            print("  –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–ø–æ–ª–Ω–∏—Ç–µ: pip install torch diffusers transformers accelerate")
            self.use_local = False
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            self.use_local = False

    def process(self, image_path: Path) -> Path:
        """
        –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ–≥–æ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É
        –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –Ω–æ–≤–æ–º—É —Ñ–∞–π–ª—É.
        """
        if not image_path.exists():
            return image_path

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ —Ñ–∞–π–ª—ã –∏–ª–∏ –∏–∫–æ–Ω–∫–∏
        if image_path.stat().st_size < 5000:
            return image_path
            
        print(f"  üé® –ú–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è: {image_path.name}...")
        
        # --- –õ–û–ö–ê–õ–¨–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø ---
        if self.use_local:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à, —á—Ç–æ–±—ã –Ω–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ
            modern_path = image_path.parent / f"modern_{image_path.stem}.png"
            if modern_path.exists():
                print(f"    ‚ú® –í–∑—è—Ç–æ –∏–∑ –∫—ç—à–∞: {modern_path.name}")
                return modern_path

            self._init_local_pipeline()
            if self.pipeline:
                try:
                    from PIL import Image
                    init_image = Image.open(image_path).convert("RGB")
                    
                    # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–¥ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è SD (–∫—Ä–∞—Ç–Ω–æ—Å—Ç—å 64)
                    w, h = init_image.size
                    w = max(64, round(w / 64) * 64)
                    h = max(64, round(h / 64) * 64)
                    init_image = init_image.resize((w, h))
                    
                    generator = torch.manual_seed(42) if 'torch' in locals() else None
                    
                    image = self.pipeline(
                        prompt=self.style_prompt,
                        negative_prompt=self.negative_prompt,
                        image=init_image,
                        strength=0.35, # –°–∏–ª–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π (–±–æ–ª—å—à–µ -> —Å–∏–ª—å–Ω–µ–µ –º–µ–Ω—è–µ—Ç—Å—è)
                        guidance_scale=7.5,
                        num_inference_steps=30,
                        generator=generator
                    ).images[0]
                    
                    modern_path = image_path.parent / f"modern_{image_path.stem}.png"
                    image.save(modern_path)
                    print(f"    ‚ú® –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {modern_path.name}")
                    return modern_path
                    
                except Exception as e:
                    print(f"  ‚ö† –û—à–∏–±–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
                    return image_path
            else:
                 # –ï—Å–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
                 return image_path

        # --- –í–ê–†–ò–ê–ù–¢: STABILITY AI API ---
        # –ü–æ–¥—Ä–æ–±–Ω–µ–µ: https://platform.stability.ai/docs/api-reference#tag/v1generation/operation/imageToImage
        if self.api_key:
            import requests
            url = "https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/image-to-image"
            
            try:
                response = requests.post(
                    url,
                    headers={
                        "Accept": "application/json",
                        "Authorization": f"Bearer {self.api_key}"
                    },
                    files={
                        "init_image": open(image_path, "rb")
                    },
                    data={
                        "init_image_mode": "IMAGE_STRENGTH",
                        "image_strength": 0.35, 
                        "text_prompts[0][text]": self.style_prompt,
                        "text_prompts[0][weight]": 1,
                        "text_prompts[1][text]": self.negative_prompt,
                        "text_prompts[1][weight]": -1,
                        "samples": 1,
                        "steps": 30,
                    }
                )
                
                if response.status_code != 200:
                    print(f"  ‚ö† –û—à–∏–±–∫–∞ API: {response.text}")
                    return image_path

                data = response.json()
                import base64
                
                for i, image in enumerate(data.get("artifacts", [])):
                    modern_path = image_path.parent / f"modern_{image_path.stem}.png"
                    with open(modern_path, "wb") as f:
                        f.write(base64.b64decode(image["base64"]))
                    return modern_path

            except Exception as e:
                print(f"  ‚ö† –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ—Ä–µ–∑ API: {e}")
                return image_path
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ - –ø—Ä–æ—Å—Ç–æ –∑–∞–≥–ª—É—à–∫–∞ (–≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª)
        return image_path


def process_images(post_content, files_dir: Path, files_dir_name: str, modernizer: ImageModernizer = None) -> int:
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–æ—Å—Ç–µ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–Ω—ã—Ö.
    """
    downloaded = 0
    
    for img in post_content.find_all('img'):
        # –ü–æ–ª—É—á–∞–µ–º URL (–∏–∑ src –∏–ª–∏ alt)
        src = img.get('src', '')
        alt = img.get('alt', '')
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ URL
        url = None
        for candidate in [src, alt]:
            if candidate and (candidate.startswith('http://') or candidate.startswith('https://')):
                url = fix_image_url(candidate)
                break
        
        # –ï—Å–ª–∏ URL —É–∂–µ –ª–æ–∫–∞–ª—å–Ω—ã–π - –æ—Å—Ç–∞–≤–ª—è–µ–º (–∏–ª–∏ –º–æ–¥–µ—Ä–Ω–∏–∑–∏—Ä—É–µ–º –µ—Å–ª–∏ —ç—Ç–æ —Å—Ç–∞—Ä—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª?)
        # –í –¥–∞–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑, —Ç–∞–∫ —á—Ç–æ –ª–æ–∫–∞–ª—å–Ω—ã–µ - —ç—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        if src and not src.startswith(('http://', 'https://')):
            # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –ª–æ–∫–∞–ª—å–Ω—ã–π, –∏ –≤–∫–ª—é—á–µ–Ω–∞ –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è
            if modernizer:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ HTML —Ñ–∞–π–ª–∞
                # files_dir.parent - —ç—Ç–æ –ø–∞–ø–∫–∞ –≥–¥–µ –ª–µ–∂–∏—Ç HTML
                local_path = (files_dir.parent / src)
                
                if local_path.exists():
                     processed_path = modernizer.process(local_path)
                     
                     if processed_path != local_path:
                         # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è src
                         try:
                             # –ï—Å–ª–∏ —Ñ–∞–π–ª –≤ —Ç–æ–π –∂–µ –ø–æ–¥–ø–∞–ø–∫–µ
                             new_src = processed_path.relative_to(files_dir.parent)
                             img['src'] = str(new_src)
                         except ValueError:
                             # –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ —Å –ø—É—Ç—è–º–∏, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                             pass
            continue
        
        if not url:
            img.decompose()  # –ù–µ—Ç –≤–∞–ª–∏–¥–Ω–æ–≥–æ URL - —É–¥–∞–ª—è–µ–º
            continue
        
        # –ü—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å
        local_filename = download_image(url, files_dir)
        
        if local_filename:
            local_path = files_dir / local_filename
            
            # –ú–û–î–ï–†–ù–ò–ó–ê–¶–ò–Ø
            if modernizer:
                processed_path = modernizer.process(local_path)
                # –ï—Å–ª–∏ –ø—É—Ç—å –∏–∑–º–µ–Ω–∏–ª—Å—è (—Å–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π —Ñ–∞–π–ª), –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∏–º—è
                if processed_path != local_path:
                    local_filename = processed_path.name

            # –£—Å–ø–µ—à–Ω–æ - –æ–±–Ω–æ–≤–ª—è–µ–º src
            img['src'] = f"{files_dir_name}/{local_filename}"
            img['loading'] = 'lazy'
            img['class'] = 'postimg'
            # –£–±–∏—Ä–∞–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
            for attr in ['alt', 'data-src', 'onclick']:
                if attr in img.attrs:
                    del img.attrs[attr]
            downloaded += 1
        else:
            # –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å - —É–¥–∞–ª—è–µ–º —Ç–µ–≥
            img.decompose()
    
    return downloaded


def batch_modernize_directory(directory: Path, modernizer: ImageModernizer):
    """
    –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ –∞—Ç–ª–∞—Å.
    """
    if not image_stitcher:
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    extensions = ('.jpg', '.jpeg', '.png', '.webp')
    images = [f for f in directory.iterdir() if f.suffix.lower() in extensions]
    if not images:
        return

    print(f"  üöÄ –ü–∞–∫–µ—Ç–Ω–∞—è –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è {len(images)} —Ñ–∞–π–ª–æ–≤ –≤ {directory.name}...")
    
    atlas_path = directory / "temp_atlas_processing.png"
    meta_path = directory / "temp_atlas_processing.json"
    
    # 1. –°–∫–ª–µ–π–∫–∞
    try:
        image_stitcher.stitch_images(str(directory), str(atlas_path), str(meta_path))
    except Exception as e:
        print(f"  ‚ö† –û—à–∏–±–∫–∞ —Å–∫–ª–µ–π–∫–∏: {e}")
        return

    if not atlas_path.exists():
        return

    # 2. –ú–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è
    processed_atlas = modernizer.process(atlas_path)
    
    # 3. –†–∞—Å–∫–ª–µ–π–∫–∞
    if processed_atlas and processed_atlas.exists():
        print(f"  ‚úÇ –†–∞—Å–∫–ª–µ–π–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –∞—Ç–ª–∞—Å–∞...")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º unstitch_images –∏–∑ –º–æ–¥—É–ª—è
        # –í–∞–∂–Ω–æ: unstitch –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ—Ç —Ñ–∞–π–ª—ã, –µ—Å–ª–∏ –æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç –ø–æ –∏–º–µ–Ω–∞–º –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        try:
            image_stitcher.unstitch_images(str(processed_atlas), str(meta_path))
            print("  ‚úÖ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
        except Exception as e:
            print(f"  ‚ö† –û—à–∏–±–∫–∞ —Ä–∞—Å–∫–ª–µ–π–∫–∏: {e}")

    # 4. –û—á–∏—Å—Ç–∫–∞
    try:
        if atlas_path.exists(): os.remove(atlas_path)
        if meta_path.exists(): os.remove(meta_path)
        if processed_atlas != atlas_path and processed_atlas.exists():
            os.remove(processed_atlas)
    except Exception as e:
        print(f"  ‚ö† –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")



def clean_forum_html(input_path: str, output_path: str = None) -> str:
    """
    –û—á–∏—Å—Ç–∏—Ç—å HTML —Ñ–∞–π–ª —Ñ–æ—Ä—É–º–∞ –æ—Ç –º—É—Å–æ—Ä–∞.
    
    Args:
        input_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É HTML —Ñ–∞–π–ª—É
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ None - –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π)
    
    Returns:
        –ü—É—Ç—å –∫ –æ—á–∏—â–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    input_file = Path(input_path)
    if not input_file.exists():
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}")
    
    # –ü–∞–ø–∫–∞ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    files_dir_name = input_file.stem + "_files"
    files_dir = input_file.parent / files_dir_name
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª (–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏)
    content = None
    for encoding in ['utf-8', 'windows-1251', 'cp1251', 'latin-1']:
        try:
            content = input_file.read_text(encoding=encoding)
            break
        except UnicodeDecodeError:
            continue
    
    if content is None:
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª —Å –∏–∑–≤–µ—Å—Ç–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π")
    
    # –ü–∞—Ä—Å–∏–º HTML
    soup = BeautifulSoup(content, 'html.parser')
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
    title_tag = soup.find('title')
    title = title_tag.get_text() if title_tag else "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"
    title = re.sub(r'\s*¬§\w*¬§\s*', '', title).strip()
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø–æ—Å—Ç—ã
    posts = soup.find_all('div', class_='post')
    
    if not posts:
        topic_div = soup.find('div', id=lambda x: x and x.startswith('topic_'))
        if topic_div:
            posts = topic_div.find_all('div', class_='post')
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ—Å—Ç–æ–≤
    cleaned_posts = []
    total_images = 0
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ç–æ—Ä–∞
    import os
    modernizer_api_key = os.environ.get("STABILITY_API_KEY")
    # –ü—Ä–æ—Å—Ç–µ–π—à–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º (–¥–ª—è —Ç–µ—Å—Ç–∞)
    use_local = "--local" in sys.argv
    modernizer = ImageModernizer(api_key=modernizer_api_key, use_local=use_local)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã (–ø–æ—à—Ç—É—á–Ω—ã–π –∏–ª–∏ –ø–∞–∫–µ—Ç–Ω—ã–π)
    use_batch = use_local and (image_stitcher is not None)
    
    # –ï—Å–ª–∏ –ø–∞–∫–µ—Ç–Ω—ã–π —Ä–µ–∂–∏–º - –≤ —Ü–∏–∫–ª–µ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º (–ø–µ—Ä–µ–¥–∞–µ–º None)
    loop_modernizer = None if use_batch else modernizer

    for post in posts:
        post_content = post.find('div', class_='post-content')
        if post_content:
            # 1. –û–ë–†–ê–ë–ê–¢–´–í–ê–ï–ú –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø (—Å–∫–∞—á–∏–≤–∞–µ–º)
            total_images += process_images(post_content, files_dir, files_dir_name, loop_modernizer)
            
            # 2. –£–î–ê–õ–Ø–ï–ú –ò–ú–ï–ù–ê –ê–í–¢–û–†–û–í –¶–ò–¢–ê–¢
            for cite in post_content.find_all('cite'):
                cite.decompose()
            
            # 3. –£–î–ê–õ–Ø–ï–ú "–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ..."
            for p in post_content.find_all('p', class_='lastedit'):
                p.decompose()
            
            # 4. –£–î–ê–õ–Ø–ï–ú "–ü–æ—Å—Ç X –∏–∑ Y" –º–∞—Ä–∫–µ—Ä—ã
            for span in post_content.find_all('span'):
                text = span.get_text()
                if re.match(r'–ü–æ—Å—Ç\s+\d+\s+–∏–∑\s+\d+', text):
                    span.decompose()
            
            # 5. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Å—ã–ª–∫–∏
            for a in post_content.find_all('a'):
                href = a.get('href', '')
                # –£–¥–∞–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Å—ã–ª–∫–∏
                if href.startswith('javascript:') or 'PostBgColor' in href or 'PhrasesBgcolor' in href:
                    a.replace_with(a.get_text())
                # –í–Ω–µ—à–Ω–∏–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–æ—Ä—É–º - –ø–æ–º–µ—á–∞–µ–º –∫–ª–∞—Å—Å–æ–º
                elif 'aum.mybb.ru' in href:
                    a.attrs = {'class': 'broken-link', 'data-original-href': href}
                else:
                    a.attrs = {'href': href} if href and not href.startswith('javascript:') else {}
            
            # 6. –î–æ–±–∞–≤–ª—è–µ–º onclick –¥–ª—è —Å–ø–æ–π–ª–µ—Ä–æ–≤
            for spoiler in post_content.find_all('div', class_='spoiler-box'):
                spoiler['onclick'] = "this.classList.toggle('visible')"
            
            # 7. –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Ç–µ–≥–∏
            for tag in post_content.find_all(['p', 'span', 'div']):
                if not tag.get_text(strip=True) and not tag.find_all():
                    tag.decompose()
            
            cleaned_posts.append(str(post_content))
    
    # –°–æ–±–∏—Ä–∞–µ–º —á–∏—Å—Ç—ã–π HTML
    clean_html = f"""<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
{MINIMAL_CSS}
    </style>
</head>
<body>

<h1>{title}</h1>

"""
    
    for i, post_html in enumerate(cleaned_posts, 1):
        clean_html += f"""<!-- –ü–æ—Å—Ç {i} -->
<div class="post">
{post_html}
</div>

"""
    
    clean_html += """</body>
</html>
"""
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_file = Path(output_path) if output_path else input_file
    output_file.write_text(clean_html, encoding='utf-8')
    
    output_file.write_text(clean_html, encoding='utf-8')
    
    if total_images:
        print(f"  üì∑ –°–∫–∞—á–∞–Ω–æ {total_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ {files_dir_name}/")
        
    # –ï—Å–ª–∏ –ø–∞–∫–µ—Ç–Ω—ã–π —Ä–µ–∂–∏–º –∏ –µ—Å—Ç—å —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
    if use_batch and files_dir.exists():
        batch_modernize_directory(files_dir, modernizer)
    
    return str(output_file)


def process_directory(directory: str, pattern: str = "*.html"):
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ HTML —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
    """
    dir_path = Path(directory)
    if not dir_path.is_dir():
        raise NotADirectoryError(f"–ù–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {directory}")
    
    html_files = [f for f in dir_path.glob(pattern) if not f.name.endswith('.bak')]
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(html_files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    
    for html_file in html_files:
        try:
            # –°–æ–∑–¥–∞—ë–º backup
            backup = html_file.with_suffix('.html.bak')
            if not backup.exists():
                import shutil
                shutil.copy(html_file, backup)
            
            # –û—á–∏—â–∞–µ–º
            result = clean_forum_html(str(html_file))
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            original_size = backup.stat().st_size
            new_size = Path(result).stat().st_size
            reduction = (1 - new_size / original_size) * 100
            
            print(f"‚úì {html_file.name}: {original_size/1024:.1f}KB ‚Üí {new_size/1024:.1f}KB ({reduction:.0f}% —É–º–µ–Ω—å—à–µ–Ω–∏–µ)")
        
        except Exception as e:
            print(f"‚úó {html_file.name}: {e}")


def merge_forum_pages(directory: str):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≥—Ä—É–ø–ø—ã —Ñ–∞–π–ª–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä Name.html, Name2.html...)
    –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º.
    """
    dir_path = Path(directory)
    if not dir_path.is_dir():
        raise NotADirectoryError(f"–ù–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {directory}")

    # 1. –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã
    # –ö–ª—é—á: –±–∞–∑–æ–≤–æ–µ –∏–º—è, –ó–Ω–∞—á–µ–Ω–∏–µ: —Å–ø–∏—Å–æ–∫ (–Ω–æ–º–µ—Ä, –ø—É—Ç—å)
    groups = {}
    
    # –†–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞: –ò–º—è–§–∞–π–ª–∞ + (—Ü–∏—Ñ—Ä–∞) + .html
    # –ü—Ä–∏–º–µ—Ä: "Topic" + "" + ".html" -> –Ω–æ–º–µ—Ä 1
    # "Topic" + "2" + ".html" -> –Ω–æ–º–µ—Ä 2
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∂–∞–¥–Ω—ã–π –∑–∞—Ö–≤–∞—Ç –¥–ª—è –∏–º–µ–Ω–∏, —á—Ç–æ–±—ã —Ü–∏—Ñ—Ä–∞ –≤ –∫–æ–Ω—Ü–µ –ø–æ–ø–∞–ª–∞ –≤ –≥—Ä—É–ø–ø—É 2 —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∞ –ø–µ—Ä–µ–¥ .html
    pattern = re.compile(r"^(.+?)(?:(\d+))?\.html$")
    
    files = [f for f in dir_path.glob("*.html") if not f.name.endswith('.bak') and not f.name.endswith('_merged.html')]
    
    for f in files:
        match = pattern.match(f.name)
        if match:
            base_name = match.group(1)
            # –ï—Å–ª–∏ –±–∞–∑–∞ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –¥–µ—Ñ–∏—Å –∏–ª–∏ –ø—Ä–æ–±–µ–ª, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å, —ç—Ç–æ —á–∞—Å—Ç—å –∏–º–µ–Ω–∏
            suffix = match.group(2)
            
            # –û—Å–æ–±–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: —á–∞—Å—Ç–æ –±—ã–≤–∞–µ—Ç "Name.html" –∏ "Name2.html".
            # –ï—Å–ª–∏ suffix –ø—É—Å—Ç–æ, —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ 1
            num = int(suffix) if suffix else 1
            
            if base_name not in groups:
                groups[base_name] = []
            groups[base_name].append((num, f))

    # 2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥—Ä—É–ø–ø—ã
    count_merged = 0
    for base_name, file_list in groups.items():
        if len(file_list) < 2:
            continue
            
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É
        file_list.sort(key=lambda x: x[0])
        
        print(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã '{base_name}': {[f.name for n, f in file_list]}")
        
        try:
            # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª (–æ—Å–Ω–æ–≤–Ω–æ–π)
            first_num, first_path = file_list[0]
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –∏ —á–∏—Ç–∞–µ–º
            content = None
            for encoding in ['utf-8', 'windows-1251', 'cp1251']:
                try:
                    content = first_path.read_text(encoding=encoding)
                    break
                except UnicodeDecodeError:
                    continue
            
            if not content:
                print(f"  ‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {first_path.name}")
                continue

            soup = BeautifulSoup(content, 'html.parser')
            body = soup.find('body')
            if not body:
                print(f"  ‚ö† –ù–µ—Ç body –≤ {first_path.name}")
                continue
                
            # –ò—â–µ–º –º–µ—Å—Ç–æ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ (–ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ div.post –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –≤ –∫–æ–Ω–µ—Ü)
            last_post = None
            posts = body.find_all('div', class_='post')
            if posts:
                last_post = posts[-1]
            
            # –ß–∏—Ç–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –∏ –¥–æ–±–∞–≤–ª—è–µ–º
            for num, path in file_list[1:]:
                # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª-–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
                sub_content = None
                for encoding in ['utf-8', 'windows-1251', 'cp1251']:
                    try:
                        sub_content = path.read_text(encoding=encoding)
                        break
                    except UnicodeDecodeError:
                        continue
                        
                if not sub_content:
                    continue
                    
                sub_soup = BeautifulSoup(sub_content, 'html.parser')
                sub_posts = sub_soup.find_all('div', class_='post')
                
                if not sub_posts:
                    # –ï—Å–ª–∏ –ø–æ—Å—Ç–æ–≤ –Ω–µ—Ç, –º–æ–∂–µ—Ç —Ç–∞–º –ø—Ä–æ—Å—Ç–æ –∫–æ–Ω—Ç–µ–Ω—Ç –≤ body?
                    # –ë–µ—Ä–µ–º –≤—Å—ë –∏–∑ body –∫—Ä–æ–º–µ script
                    if sub_soup.body:
                        # –£–ø—Ä–æ—â–µ–Ω–∏–µ: —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ–ª–µ–∑–Ω—ã–π
                        pass
                
                if sub_posts:
                    # –°–æ–∑–¥–∞–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
                    separator = soup.new_tag('hr')
                    separator['style'] = "border: 0; height: 1px; background: #FE99FE; opacity: 0.1; margin: 50px 0;"
                    separator['class'] = "page-separator"
                    
                    header_sep = soup.new_tag('div')
                    header_sep['style'] = "text-align: center; color: #444; font-size: 12px; margin-bottom: 20px;"
                    header_sep.string = f"--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {num} ---"
                    
                    # –í—Å—Ç–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –≤ –∫–æ–Ω–µ—Ü body (–∏–ª–∏ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ—Å—Ç–∞)
                    body.append(separator)
                    body.append(header_sep)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å—Ç—ã
                    for post in sub_posts:
                        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–¥—É –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç (BS4 –¥–µ–ª–∞–µ—Ç —ç—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –≤—Å—Ç–∞–≤–∫–µ)
                        body.append(post)
                        # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∫—Ä–∞—Å–æ—Ç—ã
                        body.append(NavigableString("\n\n"))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –Ω–æ–≤—ã–π —Ñ–∞–π–ª
            output_name = first_path.stem + "_merged.html"
            
            # --- –ö–û–ù–°–û–õ–ò–î–ê–¶–ò–Ø –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô ---
            merged_files_dir_name = Path(output_name).stem + "_files"
            merged_files_dir = dir_path / merged_files_dir_name
            merged_files_dir.mkdir(exist_ok=True)
            
            count_images = 0
            for img in soup.find_all('img'):
                src = img.get('src')
                if not src or src.startswith(('http://', 'https://', 'data:')):
                    continue
                
                # –ò—â–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
                # src –æ–±—ã—á–Ω–æ "Name_files/img.jpg", –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ html
                original_path = dir_path / src
                
                if original_path.exists() and original_path.is_file():
                    # –ö–æ–ø–∏—Ä—É–µ–º –≤ –Ω–æ–≤—É—é –ø–∞–ø–∫—É
                    new_filename = original_path.name
                    destination = merged_files_dir / new_filename
                    
                    if not destination.exists():
                        try:
                            shutil.copy2(original_path, destination)
                        except Exception as e:
                            print(f"    ‚ö† –û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è {new_filename}: {e}")
                            continue

                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É
                    img['src'] = f"{merged_files_dir_name}/{new_filename}"
                    count_images += 1
            
            output_path = dir_path / output_name
            output_path.write_text(str(soup), encoding='utf-8')
            print(f"  ‚úì –°–æ–∑–¥–∞–Ω: {output_name} ({output_path.stat().st_size/1024:.1f} KB)")
            if count_images:
                print(f"    üì∑ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ {count_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ {merged_files_dir_name}/")
            count_merged += 1
            
        except Exception as e:
            print(f"  ‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏: {e}")
            import traceback
            traceback.print_exc()

    if count_merged == 0:
        print("–ì—Ä—É–ø–ø —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
    else:
        print(f"–í—Å–µ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–æ –≥—Ä—É–ø–ø: {count_merged}")



if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("""
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
  python clean_forum_html.py <—Ñ–∞–π–ª.html> [–æ–ø—Ü–∏–∏]          # –û—á–∏—Å—Ç–∏—Ç—å –æ–¥–∏–Ω —Ñ–∞–π–ª
  python clean_forum_html.py <–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è> [–æ–ø—Ü–∏–∏]         # –û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ .html –≤ –ø–∞–ø–∫–µ
  python clean_forum_html.py <—Ñ–∞–π–ª.html> <–≤—ã—Ö–æ–¥> [–æ–ø—Ü–∏–∏]  # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª
        
–û–ø—Ü–∏–∏:
  --merge   –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≥—Ä—É–ø–ø—ã —Ñ–∞–π–ª–æ–≤ (Name.html + Name2.html)
  --local   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (Stable Diffusion)
        
–ü—Ä–∏–º–µ—Ä—ã:
  python clean_forum_html.py pages/ --local
  python clean_forum_html.py --merge pages/
""")
        sys.exit(1)
    
    # –†–∞–∑–¥–µ–ª—è–µ–º —Ñ–ª–∞–≥–∏ –∏ –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    args = sys.argv[1:]
    flags = [a for a in args if a.startswith('--')]
    positional = [a for a in args if not a.startswith('--')]
    
    if not positional:
         print("‚úó –ù–µ —É–∫–∞–∑–∞–Ω —Ü–µ–ª–µ–≤–æ–π —Ñ–∞–π–ª –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è")
         sys.exit(1)
         
    target = positional[0]
    
    if '--merge' in flags:
        merge_forum_pages(target)
    elif Path(target).is_dir():
        process_directory(target)
    elif Path(target).is_file():
        output = positional[1] if len(positional) > 1 else None
        result = clean_forum_html(target, output)
        print(f"‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {result}")
    else:
        print(f"‚úó –ù–µ –Ω–∞–π–¥–µ–Ω–æ: {target}")
        sys.exit(1)
