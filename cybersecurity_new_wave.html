<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Киберугрозы: новая волна ИИ-мошенничества</title>
  <style>
    body {
      background-color: #121212;
      color: #ddd;
      font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
      margin: 0;
      padding: 0;
      line-height: 1.6;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      padding: 1.5rem;
    }
    h1, h2, h3, h4 {
      color: #ddd;
      margin-top: 2rem;
      margin-bottom: 1rem;
      line-height: 1.3;
    }
    h1 {
      font-size: 2rem;
      text-align: center;
      margin-top: 1rem;
    }
    h2 {
      font-size: 1.5rem;
      border-left: 4px solid #14b8a6;
      padding-left: 0.5rem;
      color: #60a5fa;
    }
    h3 {
      font-size: 1.25rem;
      color: #60a5fa;
      margin-top: 1.5rem;
      margin-bottom: 1rem;
    }
    p {
      margin-bottom: 1rem;
    }
    a {
      color: #60a5fa;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    .card {
      background-color: #1e1e1e;
      padding: 1rem 1.5rem;
      margin: 1.5rem 0;
      border-radius: 8px;
      box-shadow: 0 4px 8px rgba(0,0,0,0.3);
    }
    .card p {
      margin-bottom: 0.8rem;
    }
    figure {
      text-align: center;
      margin: 2rem 0;
    }
    figure img {
      max-width: 100%;
      height: auto;
      border-radius: 4px;
    }
    figure figcaption {
      color: #999;
      font-size: 0.9rem;
      margin-top: 0.5rem;
    }
    @media (min-width: 768px) {
      .cards-grid {
        display: grid;
        grid-template-columns: repeat(2, 1fr);
        gap: 1rem;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Киберугрозы: новая волна ИИ-мошенничества</h1>
    <p>Современные киберпреступники осваивают генеративный ИИ. Если раньше фишинговые письма и переписки часто выдавали себя плохим языком, то теперь мошенники могут автоматизировать обманчиво правдоподобные сообщения. В этом разделе рассмотрим несколько реальных кейсов из разных стран, где текстовые нейросети стали орудием аферы.</p>

    <h2>Новая волна: обман через текстовых ИИ</h2>
    <figure>
      <figcaption>Преступники используют возможности генеративного ИИ (например, ChatGPT), чтобы создавать более убедительные письма и сообщения для своих махинаций.</figcaption>
    </figure>
    <div class="cards-grid">
      <!-- Card 1 -->
      <div class="card">
        <h3>Романтическая уловка разоблачена «оговоркой» ChatGPT</h3>
        <p>**Великобритания, 2023.** Молодой мужчина познакомился с жертвой в приложении для языкового обмена Tandem, выдавая себя за потенциального романтического партнёра. Переписка вскоре перешла в WhatsApp, где злоумышленник использовал ChatGPT для написания длинных проникновенных сообщений. Однако одна из таких тирад выдала мошенника: сообщение начиналось с фразы *«Как языковая модель ‘меня’, у меня нет чувств…»*, явно скопированной из ответа ChatGPT. Жертва сразу насторожилась и поняла, что имеет дело с искусственным интеллектом, а не реальным человеком. В итоге попытка обмана провалилась, и аферисты не успели склонить её к каким-либо финансовым действиям. Эксперты Sophos отметили, что подобная схема была прологом к так называемому CryptoRom – разновидности «pig butchering» («откорма порося») с целью выманить деньги под видом инвестиций в криптовалюты, но бдительность жертвы сорвала план злоумышленников.</p>
        <p><small>Источник: исследование компании Sophos</small></p>
      </div>

      <!-- Card 2 -->
      <div class="card">
        <h3>«Фабрика» мошенников в Азии: ChatGPT на службе рабовладельцев</h3>
        <p>**Юго-Восточная Азия, 2022–2023.** 26-летний кениец Данкан Окиндо, надеясь на законную работу, был обманом заманен в Таиланд, где оказался пленником в печально известном приграничном комплексе KK Park на границе Мьянмы. В лагере, контролируемом преступными группировками, сотни людей принуждали заниматься интернет-мошенничеством под угрозой побоев. Окиндо вспоминает, что самым популярным инструментом там был бесплатный ChatGPT – с его помощью пленники сочиняли правдоподобные тексты от имени вымышленных лиц. Сам Окиндо по указке кураторов искал в интернете контакты американских риэлторов и ежедневно пытался убедить как минимум двоих из них вложиться в фиктивную криптовалютную платформу. ChatGPT позволял ему без усилий писать по-английски, имитируя стиль речи местных жителей (например, богатого техасского фермера), и даже отвечать на неожиданные вопросы жертв – он копировал вопросы в чат-бот и тут же получал правдоподобный ответ для пересылки. Такая схема «свиного откорма» (pig butchering) позволила мошенникам обманом заставить многих иностранцев вложить крупные суммы, пока силовики не разоблачили лагерь и не освободили Окиндо и других узников. По словам Окиндо, ChatGPT стал «основным инструментом, с помощью которого мошенники делали своё дело» в этом конвейере обмана.</p>
        <p><small>Источник: репортаж Reuters</small></p>
      </div>

      <!-- Card 3 -->
      <div class="card">
        <h3>Афера «Неправильный номер»: ложные вакансии от имени ИИ</h3>
        <p>**Глобально, 2025.** Компания OpenAI раскрыла международную мошенническую операцию под кодовым названием *«Wrong Number»*, в которой её ИИ-модель ChatGPT использовалась для массовой рассылки фальшивых предложений о работе. Жертвам обещали нереально высокую оплату – более $5 за каждый лайк в соцсетях, тогда как обычно тысяча лайков стоит меньше $10. По схеме злоумышленники сначала «пинговали» жертву этим заманчивым предложением, затем, завоевав доверие, выплачивали небольшие суммы и демонстрировали поддельные отзывы от «довольных сотрудников» для правдоподобности. Наконец, когда жертва была уверена в реальности заработка, её просили заплатить какой-то взнос – например, купить криптовалюту или оплатить «вступительный сбор» – после чего связь обрывалась, а деньги присваивались мошенниками. Во многих странах люди попадались на этот трюк, доверяя грамотно составленным чат-ботом многоязычным сообщениям. Операция была разоблачена благодаря сотрудникам OpenAI: один из исследователей сам получил подобный спам по SMS, заподозрил неладное и проследил цепочку до преступной группировки. Этот кейс показал, как ИИ способен автоматизировать и масштабировать социальную инженерию.</p>
        <p><small>Источник: отчет OpenAI</small></p>
      </div>

      <!-- Card 4 -->
      <div class="card">
        <h3>Выдавая себя за власть: ИИ-атаки на чиновников</h3>
        <p>**США, 2025.** ФБР выпустило предупреждение об утончённой мошеннической кампании, где злоумышленники имитируют высокопоставленных лиц с помощью искусственного интеллекта. С апреля 2025 года фиксируются массовые рассылки текстовых и голосовых сообщений, будто бы исходящих от известных государственных чиновников США. В действительности это ИИ-сгенерированные обращения, цель которых – войти в доверие и выманить у адресата конфиденциальные данные или заставить перейти по вредоносной ссылке. В группе риска оказались сами чиновники (нынешние и бывшие), а также их знакомые и подчинённые. Один из эпизодов произошёл в штате Юта: жителю пришло электронное письмо якобы от городской полиции Солт-Лейк-Сити с видеороликом, где голос начальника полиции Майка Брауна сообщал об ошибочном переводе и требовал доплаты $100 тысяч в бюджет. Как выяснилось, видео было создано нейросетью на основе старого интервью Брауна, а голос искусственно скопирован (deepfake). Хотя интонации местами звучали неестественно, многие могли принять такое обращение за правду и поспешить выполнить указания. ФБР отмечает, что получение внезапных сообщений даже от знакомых официальных лиц должно вызвать подозрение, и советует всегда перепроверять информацию через независимые каналы.</p>
        <p><small>Источник: PSA ФБР; пресс-релиз полиции Солт-Лейк-Сити</small></p>
      </div>

      <!-- Card 5 -->
      <div class="card">
        <h3>Грамотный фишинг в России: нейросеть вместо «кряжистого» текста</h3>
        <p>**Россия, 2023.** Отечественные эксперты по кибербезопасности бьют тревогу: мошенники научились использовать ChatGPT для создания фишинговых писем без привычных раньше грубых ошибок. Управляющий директор «Лаборатории Касперского» Анна Кулашова отметила, что раньше многие поддельные сообщения выдавал низкий уровень русского языка, но теперь нейросеть помогает злоумышленникам быстро исправлять формулировки и грамматику. Жертва может получить электронное письмо, практически не отличимое от официальной рассылки банка или государственной службы – с безупречным языком, верными обращениями и фирменными стилевыми элементами. Полагаясь на такое убедительное письмо, получатель переходит по вложенной ссылке и попадает на фишинговый сайт, где вводит свои учетные данные, думая, что проходит проверку безопасности. В результате, по данным Роскомнадзора, число фишинговых ресурсов в рунете резко выросло: только за первый квартал 2023 года было заблокировано более 7200 таких сайтов (на  ~ значительный процент больше, чем годом ранее). Данная «эволюция» фишинга затрудняет борьбу с ним, однако эксперты призывают пользователей сохранять скепсис даже к хорошо написанным письмам, если они содержат просьбы о вводе данных.</p>
        <p><small>Источник: Коммерсантъ</small></p>
      </div>

      <!-- Card 6 -->
      <div class="card">
        <h3>Звонок от «банкира»: кража £60 000 через письмо и чат-бот</h3>
        <p>**Великобритания, 2023.** В начале года клиентка Santander UK стала жертвой изощрённой схемы: ей позвонили мошенники, представившись руководителем службы кибербезопасности банка – Крисом Эйнсли. Накануне женщина получила SMS якобы от банка с просьбой подтвердить перевод £500; она ответила отказом, заподозрив мошенни&shy;чество. Тогда аферисты перешли в наступление: используя технологию подмены номера, они позвонили под видом официальной линии Santander. Лжесотрудник (представившийся тем самым Эйнсли) убедительно сообщил, что на её счёте пытаются украсть деньги, и порекомендовал срочно переместить все средства на «новый безопасный счёт». В панике женщина перевела злоумышленникам около £60 000 своими руками. Позже банк возместил потерю, но отметил, что за первые три месяца 2023 года объём мошенничеств с выдачей себя за доверенных лиц вырос на 11%, причинив ущерб свыше £10,2 млн (в среднем ~£6900 на жертву). Примечательно, что аферисты не постеснялись использовать имя реального главы отдела борьбы с мошенничеством Santander – случай, который сам Эйнсли назвал далёким от «лестного подражания», но весьма показательным.</p>
        <p><small>Источник: Computer Weekly</small></p>
      </div>
    </div> <!-- .cards-grid -->
  </div> <!-- .container -->
</body>
</html>
